---
title: "resultsBcsEm"
output: rmarkdown::html_vignette
bibliography: ukhe.bib
vignette: >
  %\VignetteIndexEntry{resultsBcsEm}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.dim = c(10,6),
  out.width = "100%",
  warning = FALSE
)
```

```{r setup}
# library(ukheEm)
library(ggplot2)
library(ggrepel)
library(here)

devtools::load_all()

# functions
saveFig <- function(x, ...) ggsave(here(figDir, x), width = 10, height = 6)

resBcs <- resBcsBoth_md
maxK1 <- 4 # parental income
maxK2 <- 6 # cognitive score

maxK <- 12

# directories
figDir <- "vignettes/fig/BcsBoth_md"
dir.create(here(figDir))
```

This vignette analyses the results of running `progUkheEm()` on the BCS data. The algorithm is presented in detail in @cassagneau-francis_role_2021, and builds on the work in @cassagneau-francis_nonparametric_2020.

```{r combine results in big dt}

bigDt <- list()
i <- 1
for (K1 in 2:maxK1) {
  for (K2 in 2:maxK2) {
    bigDt[[i]] <- resBcs[[i]][[3]]
    bigDt[[i]][, paste0("nTypes", 1:2) := .(K1, K2)]
    if (i == maxK) break
    i <- i+1
  }
}

bigDt <- rbindlist(bigDt)

# reorder types by mu
bigDt[, paste0("oldType", c("", 1, 2)) := .(type, type1, type2)]
bigDt[, nTypes := paste0(nTypes1, nTypes2)]
bigDt[, type1 := frank(alpha1, ties.method = "dense"), by = .(nTypes)]
bigDt[, type2 := frank(alpha2, ties.method = "dense"), by = .(nTypes)]
bigDt[, type := factor(paste0(type1, type2))]
setorder(bigDt, nTypes, type, id)

# save number of individuals
NN <- bigDt[nTypes == "22" & type == "11", .N]
```

# Choosing the number of types (K)

```{r dtLikeConverge}

dtLikeConverge <- list()
i <- 1
for (K1 in 2:maxK1) {
  for (K2 in 2:maxK2) {
    dtLikeConverge[[i]] <- data.table(
      nTypes1 = K1, nTypes2 = K2,
      iter = 1:length(resBcs[[i]]$listLoglike),
      logLikelihood = unlist(resBcs[[i]]$listLoglike)
    )
    if (i == maxK) break
    i <- i+1
  }
}

dtLikeConverge <- rbindlist(dtLikeConverge)
dtLikeConverge[, maxIter := max(iter), by = .(nTypes1, nTypes2)]
dtLikeConverge[, nTypes := paste0(nTypes1, nTypes2)]

```

## Convergence

```{r llhood convergence plots}

ggplot(data = dtLikeConverge,
       mapping = aes(x = iter, y = logLikelihood, colour = factor(nTypes))) +
  geom_line() +
  geom_label_repel(data = dtLikeConverge[iter == maxIter, ], 
            mapping = aes(x = iter, 
                          y = logLikelihood, label = paste0("K = ", nTypes)),
            nudge_x = 50, segment.alpha = .6) +
  facet_grid(rows = vars(nTypes1), cols = vars(nTypes2)) +
  scale_x_continuous(name = "Iteration") +
  scale_y_continuous(name = "Log-likelihood") +
  theme_classic() + theme(text = element_text(size = 15)) +
  guides(colour = "none")

saveFig("likelihoodConverge.png")
```

## Likelihood criteria

We use four criteria to help select the number of types:

- log-likelihood, $\ln\mathcal{L}$
- AIC ($\ln\mathcal{L} - j$) 
- BIC ($\ln\mathcal{L} - \frac{j}{2}\ln{N}$)
- ICL (see @biernacki_assessing_2000)

where $j$ is the number of estimated parameters and $N$ the number of observations. 

The parameters are:
$$
\Theta_K = \left\{\underset{4 \times K}{\mu(k), \mu_B(k), \sigma_{\nu}(k), \sigma_{\nu B}(k)}, \left\{ \underset{2 \times 2 \times K}{\alpha(k,d),\sigma_{\epsilon}(k,d)}, \left\{ \underset{4 \times K}{\pi(k,z,d)} \right\}_{z=0}^1\right\}_{d=0}^1 \right\}_{k=1}^K
$$
meaning $j = \#\Theta_K = (4 + 2 \times 2 + 4) \times K = 12K$

```{r likelihood criteria}

dtLikelihood <- dtLikeConverge[iter == maxIter, 
                               .(nTypes, nTypes1, nTypes2, iter, logLikelihood)]
dtLikelihood[, `:=` (
  AIC = logLikelihood - 12 * nTypes1 * nTypes2,
  BIC = logLikelihood - 12 * nTypes1 * nTypes2 / 2 * log(NN)
)]

dtLikelihood <- melt(
  dtLikelihood,
  id.vars = c("nTypes", paste0("nTypes", 1:2), "iter"),
  variable.name = "criteria"
)

dtLikelihood[iter == 399, maxIter := TRUE]

nTypesLevels <- dtLikelihood[, unique(nTypes)]
nTypesLevels <- nTypesLevels[
  order(as.numeric(substr(nTypesLevels, 1, 1)) + as.numeric(substr(nTypesLevels, 2, 2)))
]

dtLikelihood[, nTypes := factor(nTypes, nTypesLevels)]


ggplot(
  data = dtLikelihood,
  mapping = aes(x = nTypes, y = value, colour = criteria, group = criteria)
) +
  geom_line() +
  geom_point(aes(shape = maxIter), size = 1.5) +
  facet_wrap(vars(criteria), nrow = 2, scale = "free") +
  scale_x_discrete(name = "Number of types (K1, K2)") +
  scale_y_continuous(name = NULL) +
  scale_shape_manual(
    name = NULL, labels = "Reached max. \niterations (400)",
    values = 1, breaks = TRUE
  ) +
  theme_classic() + 
  theme(legend.position = c(.75,.25), text = element_text(size = 15)) +
  guides(colour = "none")

saveFig("likelihoodCriteria.png")
```

## Posterior probabilities

```{r pk plot}

ggplot(
  data = bigDt, 
  mapping = aes(x = pk, fill = type)
) +
  geom_histogram() +
  facet_grid(nTypes1 ~ nTypes2, scale = "free") +
  scale_y_continuous(name = NULL) +
  # scale_x_continuous(limits = c(.05, 1)) +
  theme_classic() +
  theme(text = element_text(size = 15)) +
  guides(fill = "none") +
  coord_cartesian(ylim = c(0, 500))

saveFig("pkPlot.png")

```

## Size (and means) of groups

The groups sizes are reasonable, and the algorithm sorts strongly. 

```{r groups size and means}

dtPk <- bigDt[, .(
  P_k = sum(pk) / .N,
  alpha1 = mean(alpha1),
  alpha2 = Hmisc::wtd.mean(y2, pk),
  muCons = Hmisc::wtd.mean(w, pk)
), by = .(nTypes, type)]

dtPk[, alpha1Norm := (alpha1 - mean(alpha1)) / sd(alpha1)]
dtPk[, alpha2Norm := (alpha2 - mean(alpha2)) / sd(alpha2)]
dtPk[, muConsNorm := (muCons - mean(muCons)) / sd(muCons)]

dtPk <- melt(
  dtPk, 
  measure.vars = c("alpha1Norm", "alpha2Norm", "muConsNorm")
)

ggplot(
  data = dtPk,
  mapping = aes(x = type)
) +
  geom_col(aes(y = P_k / 2)) +
  geom_point(aes(y = (value + 4)/6, colour = variable)) +
  facet_grid(rows = vars(nTypes1), cols = vars(nTypes2)) +
  scale_x_discrete(name = "Type (k)") +
  scale_y_continuous(
    name = "Pr(k)",
    sec.axis = sec_axis(trans = ~. * 5 - 4)
  ) +
  scale_color_manual(name = NULL, 
                     limits = c("alpha1Norm", "alpha2Norm", "muConsNorm"),
                     labels = c("Parental Inc. @16", "Test score", "Wage @25"),
                     values = c("red", "blue", "green")) +
  theme_classic() +
  theme(legend.position = "bottom", text = element_text(size = 15))

saveFig("groupSizesMeansK2_K7.png")




```

## Type-specific graduate wage-premium at 25

```{r wp} 

dtWagePrem <- bigDt[, .(
  alpha2d = Hmisc::wtd.mean(y2, pk),
  mu = Hmisc::wtd.mean(w, pk)
), by = .(nTypes, type, d)]

dtWagePrem <- dcast(dtWagePrem, 
                    formula = nTypes + type ~ d, 
                    value.var = c("alpha2d", "mu"))

# setnames(dtWagePrem, old = c("FALSE", "TRUE"), new = c("alpha_FALSE", "alpha_TRUE"))

dtWagePrem[, testPrem := log(alpha2d_TRUE) - log(alpha2d_FALSE)]
dtWagePrem[, wagePrem := mu_TRUE - mu_FALSE]

dtWagePrem <- merge(dtWagePrem, 
                    dtPk[variable == "alpha1Norm", .(nTypes, type, alpha1, P_k)],
                    by = c("nTypes", "type"))

# dtWagePrem <- melt(dtWagePrem, 
#                    measure.vars = c("testPrem", "wagePrem"))

ggplot(data = dtWagePrem,
       mapping = aes(x = type, alpha = P_k)) +
  geom_col(aes(y = wagePrem, fill = "Wage", colour = "Wage")) +
  geom_col(aes(y = testPrem, fill = "Test", colour = "Test")) +
  facet_wrap(vars(nTypes), nrow = 2) +
  scale_x_discrete(name = "Type (k)") +
  scale_y_continuous(name = "% difference") +
  scale_fill_manual(name = "Premia",
                    values = c("red", NA),
                    limits = c("Wage", "Test")) +
  scale_colour_manual(name = "Premia",
                      values = c(NA, "blue"),
                      limits = c("Wage", "Test")) +
  scale_alpha_continuous(name = "Pr(k)") +
  theme_classic() +
  theme(text = element_text(size = 15)) 


saveFig("wagePrem.png")

```

```{r unconditional ATEs}

dtWPuncond <- merge(
  dtWagePrem,
  bigDt[d == TRUE, .(
    P_kdT = sum(pk) / .N
  ), by = .(nTypes, type)],
  by = c("nTypes", "type")
) %>% 
  .[, .(
  WPu = sum(P_k * wagePrem),
  WPu_dT = sum(P_kdT * wagePrem)
), by = nTypes]


ggplot(data = dtWPuncond,
       mapping = aes(x = nTypes)) +
  geom_col(aes(y = WPu, fill = "ATE", colour = "ATE")) +
  geom_col(aes(y = WPu_dT, fill = "ATT", colour = "ATT")) +
  scale_x_discrete(name = "Number of types (K)") +
  scale_y_continuous(name = "") +
  scale_fill_manual(name = "",
                    values = c("red", NA),
                    limits = c("ATE", "ATT")) +
  scale_colour_manual(name = "",
                      values = c(NA, "blue"),
                      limits = c("ATE", "ATT")) +
  theme_classic() +
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

saveFig("uncondWP.png")

```


## Pr(k,d)

The bottom group remains a similar size as we increase K

```{r p_kd}

types2Drop <- bigDt[, sum(pk), by = .(nTypes, type, d)][
  V1 < .Machine$double.eps][, paste0(nTypes, type, d)]



dtPkd <- bigDt[!(paste0(nTypes, type, d) %in% types2Drop), .(
  nTypes1 = unique(nTypes1), nTypes2 = unique(nTypes2),
  P_kd = sum(pk) / NN,
  alpha2d = Hmisc::wtd.mean(y2, pk),
  sigmaY2d = sqrt(Hmisc::wtd.var(y2, pk, normwt = TRUE)),
  alpha1 = mean(alpha1), sigmaY1 = mean(sigmaY1),
  mu = Hmisc::wtd.mean(w, pk),
  sigmaW = sqrt(Hmisc::wtd.var(w, pk, normwt = TRUE))
), by = .(nTypes, type, d)]

dtPkd[, muNorm := (mu - mean(mu)) / sd(mu)]
dtPkd[, alpha1Norm := (alpha1 - mean(alpha1)) / sd(alpha1)]
dtPkd[, alpha2dNorm := (alpha2d - mean(alpha2d)) / sd(alpha2d)]

ggplot(
  data = dtPkd,
  mapping = aes(x = type, fill = d)
) +
  geom_col(aes(y = P_kd)) +
  geom_point(aes(y = (alpha1Norm + 4)/6, shape = "Parental Inc. @16"), stroke = .3) +
  geom_point(aes(y = (alpha2dNorm + 4)/6, shape = "Test score @16"), stroke = .3) +
  # geom_point(aes(y = (muNorm + 4)/6, shape = "log-wage (@25)"), stroke = .3) +
  facet_grid(rows = vars(nTypes1), cols = vars(nTypes2)) +
  scale_y_continuous(name = "Pr(k,d)") +
  scale_shape_manual(name = NULL,
                     limits = c(
                       "Parental Inc. @16", 
                       "Test score @16", 
                       "log-wage (@25)"
                     ),
                     values = c(21, 22, 24)) +
  theme_classic() +
  guides(shape = guide_legend())+
  theme(text = element_text(size = 15), legend.position = "bottom")

saveFig("Prkd.png")

```

## Analysing groups based on observables 

### Assigning types

```{r assign types}

bigDt[, maxPk := max(pk), by = .(nTypes, id)]

dtAssignedTypes <- bigDt[pk == maxPk, ]

```

### Assigned groups: means and sizes

```{r assigned group sizes and means}

dtATPkd <- dtAssignedTypes[, .(
  P_kd_AT = .N / NN,
  mu = mean(mu),
  alpha = mean(y2)
), by = .(nTypes, type, d)]

dtATPkd[, `:=` (
  muNorm = (mu - mean(mu)) / sd(mu),
  alphaNorm = (alpha - mean(alpha)) / sd(alpha)
)]

ggplot(
  data = dtATPkd[nTypes %between% c(2, 9), ],
  mapping = aes(x = type, fill = d)
) +
  geom_col(aes(y = P_kd_AT)) +
  geom_point(aes(y = (muNorm + 4)/6, shape = "Parental Inc. @16"), stroke = .3) +
  geom_point(aes(y = (alphaNorm + 4)/6, shape = "log-wage (@25)"), stroke = .3) +
  facet_wrap(vars(nTypes), nrow = 2) +
  scale_y_continuous(name = "Pr(k,d)") +
  scale_shape_manual(name = NULL,
                     breaks = c("Parental Inc. @16", "log-wage (@25)"),
                     values = c(21, 24),
                     labels = c("Parental Inc. @16", "log-wage (@25)")) +
  theme_classic() +
  guides(shape = guide_legend()) +
  theme(text = element_text(size = 15), legend.position = "bottom")

saveFig("PrkdK2_K9_assgndTypes.png")

```

### Merging with observed characteristics

```{r observed characteristics}

dtBcsWorkerFirm <- bcs70$bcs1996x[, .(
  id = bcsid, sex, degree,
  yrJobStart = b960270,
  inCouple = b960319,
  married = b960322,
  livingSitn = b960321,
  nbKids = b960333,
  age = b960338,
  health = b960432,
  soc, seg91, rgsc91, isco, goldth90, hgscale, # occupation / socio-econ classes
  noVocQual = no_qual,
  ol_ac, ol_de, gcse_ac, gcse_de, # O-level / GCSE grades
  alevel, slevel, # A-level / S-level passes,
  hed, pgce, opgc, postgrad, found, dip_un, other_ac, # academic qualifications
  nvq_1, nvq_2, nvq_3, nvq_4, nvq_5, nvq_6, # nvqs at levels
  ageLeftSchl = b960129, ageLeftFtEd = b960132,
  trainCourse = b960134, yts = b960137, employerTrain = b960143, # traininig since end fte
  lengthUnemp = b960258, 
  usualHoursWk = b960277, 
  firmSize = b960272
)]

dtAssignedTypes <- merge(
  dtAssignedTypes[, .(nTypes, id, mu, sigmaNu, y2, z, d, type, pk)], 
  dtBcsWorkerFirm, 
  by = "id"
)

```


```{r table by type K2 to K4}

dtByTypeK2_4 <- dtAssignedTypes[nTypes %between% c(2, 4), .(
  "Par. Inc. @16 (mean)" = mean(exp(mu)),
  "Par. Inc. (std dev.)" = exp(mean(sigmaNu)),
  "Wage (mean)" = mean(exp(y2)),
  "Wage (std dev.)" = sd(exp(y2)),
  "Degree" = mean(d),
  "Male" = mean(sex %like% "Male"),
  "In relationship" = mean(inCouple %like% "Yes"),
  "Married" = mean(married %in% c("Married - 1st", "Remarried - 2nd+")),
  "Divorced" = mean(married %in% c("Separated", "Divorced")),
  "Live w/ partner" = mean(livingSitn %in% c("Living with spouse", 
                                             "Living as a couple")),
  "Has children" = mean(nbKids %in% paste0(1:5)),
  "Num. of children" = mean(as.numeric(paste0(nbKids)), na.rm = TRUE), 
  "In good health" = mean(health %in% c("Excellent", "Good")),
  "Occupation data" = mean(!is.na(hgscale)),
  "H-G score" = mean(hgscale, na.rm = TRUE),
  "Age left schl" = mean(as.numeric(paste0(ageLeftSchl)), na.rm = TRUE), 
  "Age left ft ed." = mean(as.numeric(paste0(ageLeftFtEd)), na.rm = TRUE),
  "Ever unemp." = mean(lengthUnemp %in% c(
    "3 months or less", "4-6 months", "7-11 months", "1-2 years", 
    "More than 2 years"
  )),
  "Hours per week" = mean(as.numeric(paste0(usualHoursWk)), na.rm = TRUE),
  "10 or less" = mean(firmSize %like% "10 or less"), 
  "11--25" = mean(firmSize %like% "11 - 25"),
  "26--99" = mean(firmSize %like% "26 - 99"),
  "100--499" = mean(firmSize %like% "100 - 499"),
  "500 or more" = mean(firmSize %like% "500 or more"),
  .N
), by = .(nTypes, type)]

setorder(dtByTypeK2_4, nTypes, type)

dtByTypeK2_4[, names(dtByTypeK2_4) := lapply(.SD, signif2), 
             .SDcols = names(dtByTypeK2_4)]

dtByTypeK2_4 <- as.data.table(t(dtByTypeK2_4), keep.rownames = TRUE)

xtable::xtable(dtByTypeK2_4, digits = 2)

knitr::kable(dtByTypeK2_4)
```

```{r table by type K5 to K6}

dtByTypeK5_6 <- dtAssignedTypes[nTypes %in% c(5, 6), .(
  "Par. Inc. @16 (mean)" = exp(mean(mu)),
  "Par. Inc. (std dev.)" = exp(mean(sigmaNu)),
  "Wage (mean)" = mean(exp(y2)),
  "Wage (std dev.)" = sd(exp(y2)),
  "Degree" = mean(d),
  "Male" = mean(sex %like% "Male"),
  "In relationship" = mean(inCouple %like% "Yes"),
  "Married" = mean(married %in% c("Married - 1st", "Remarried - 2nd+")),
  "Divorced" = mean(married %in% c("Separated", "Divorced")),
  "Live w/ partner" = mean(livingSitn %in% c("Living with spouse", 
                                             "Living as a couple")),
  "Has children" = mean(nbKids %in% paste0(1:5)),
  "Num. of children" = mean(as.numeric(paste0(nbKids)), na.rm = TRUE), 
  "In good health" = mean(health %in% c("Excellent", "Good")),
  "Occupation data" = mean(!is.na(hgscale)),
  "H-G score" = mean(hgscale, na.rm = TRUE),
  "Age left schl" = mean(as.numeric(paste0(ageLeftSchl)), na.rm = TRUE), 
  "Age left ft ed." = mean(as.numeric(paste0(ageLeftFtEd)), na.rm = TRUE),
  "Ever unemp." = mean(lengthUnemp %in% c(
    "3 months or less", "4-6 months", "7-11 months", "1-2 years", 
    "More than 2 years"
  )),
  "Hours per week" = mean(as.numeric(paste0(usualHoursWk)), na.rm = TRUE),
  "10 or less" = mean(firmSize %like% "10 or less"), 
  "11--25" = mean(firmSize %like% "11 - 25"),
  "26--99" = mean(firmSize %like% "26 - 99"),
  "100--499" = mean(firmSize %like% "100 - 499"),
  "500 or more" = mean(firmSize %like% "500 or more"),
  .N
), by = .(nTypes, type)]

setorder(dtByTypeK5_6, nTypes, type)

dtByTypeK5_6[, names(dtByTypeK5_6) := lapply(.SD, signif2), 
             .SDcols = names(dtByTypeK5_6)]

dtByTypeK5_6 <- as.data.table(t(dtByTypeK5_6), keep.rownames = TRUE)

xtable::xtable(dtByTypeK5_6, digits = 2)

knitr::kable(dtByTypeK5_6)
```














